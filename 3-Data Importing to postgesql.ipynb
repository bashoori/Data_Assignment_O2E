{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import psycopg2\n",
    "import logging\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "host=\"localhost\"\n",
    "database=\"ds\"\n",
    "\n",
    "\n",
    "def create_connection(db_file):    \n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(host=host,\n",
    "                        database=database,\n",
    "                        user=config.user,\n",
    "                        password=config.password\n",
    "                        )         \n",
    "        print(psycopg2.__version__)\n",
    "    except IOError  as e:\n",
    "        print(e) \n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_Resources_table(conn):\n",
    "    \n",
    "    cur = conn.cursor()    \n",
    "    drop_Resources_table = \"\"\"\n",
    "        DROP TABLE Resources;               \n",
    "        \"\"\"\n",
    "    cur.execute(drop_Resources_table)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Resources_table(conn):\n",
    "    \n",
    "    cur = conn.cursor()    \n",
    "    create_Resources_table = \"\"\"\n",
    "        \n",
    "        CREATE TABLE IF NOT EXISTS Resources (\n",
    "            Id          text PRIMARY KEY NOT NULL,\n",
    "            Link        Text,\n",
    "            Title       Text,\n",
    "            Description Text  ) \n",
    "        \n",
    "        \"\"\"\n",
    "    cur.execute(create_Resources_table)    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_from_csv_to_table(conn):\n",
    "    \n",
    "    cur = conn.cursor()    \n",
    "    data = None\n",
    "    try:\n",
    "        \n",
    "        data =  open('data/clean_resource.csv', 'r')\n",
    "        columns = data.readline().strip('\\n').split(',')      \n",
    "        cur.copy_from(data, 'Resources', sep=',', columns=('id','link', 'title', 'description'))     \n",
    "        data.close()\n",
    "        \n",
    "    except IOError:\n",
    "        logging.exception('')  \n",
    "        \n",
    "    if not data:\n",
    "        raise ValueError('No data available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_2_rows_resource(conn):\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    query1 = \"\"\"\n",
    "        SELECT * FROM Resources limit 2         \n",
    "        \"\"\"\n",
    "    cur.execute(query1) \n",
    "    rows = cur.fetchall()\n",
    " \n",
    "    for row in rows:\n",
    "          print(f\"Id: {row[0]}\\nLink:{row[1]}\\nTitle:{row[2]}\\nDescription: {row[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.6 (dt dec pq3 ext lo64)\n",
      "Here is 2 rows of table:\n",
      "Id: 06219\n",
      "Link:http://arxiv.org/abs/2102.06219\n",
      "Title: Silentium! Run-Analyse-Eradicate the Noise out of the DB/OS Stack\n",
      "Description: When multiple tenants compete for resources  database performance tends tosuffer. Yet there are scenarios where guaranteed sub-millisecond latencies arecrucial  such as in real-time data processing  IoT devices  or when operatingin safety-critical environments. In this paper  we study how to make querylatencies deterministic in the face of noise (whether caused by other tenantsor unrelated operating system tasks). We perform controlled experiments with anin-memory database engine in a multi-tenant setting  where we successivelyeradicate noisy interference from within the system software stack  to thepoint where the engine runs close to bare-metal on the underlying hardware.We show that we can achieve query latencies comparable to the database enginerunning as the sole tenant  but without noticeably impacting the workload ofcompeting tenants. We discuss these results in the context of ongoing effortsto build custom operating systems for database workloads  and point out thatfor certain use cases  the margin for improvement is rather narrow. In fact for scenarios like ours  existing operating systems might just be good enough provided that they are expertly configured. We then critically discuss thesefindings in the light of a broader family of database systems (e.g.  includingdisk-based)  and how to extend the approach of this paper accordingly.\n",
      "Id: 06228\n",
      "Link:http://arxiv.org/abs/2102.06228\n",
      "Title: Learning Gaussian-Bernoulli RBMs using Difference of Convex Functions  Optimization\n",
      "Description: The Gaussian-Bernoulli restricted Boltzmann machine (GB-RBM) is a usefulgenerative model that captures meaningful features from the given n -dimensional continuous data. The difficulties associated with learningGB-RBM are reported extensively in earlier studies. They indicate that thetraining of the GB-RBM using the current standard algorithms  namely contrastive divergence (CD) and persistent contrastive divergence (PCD)  needsa carefully chosen small learning rate to avoid divergence which  in turn results in slow learning. In this work  we alleviate such difficulties byshowing that the negative log-likelihood for a GB-RBM can be expressed as adifference of convex functions if we keep the variance of the conditionaldistribution of visible units (given hidden unit states) and the biases of thevisible units  constant. Using this  we propose a stochastic {em difference ofconvex functions} (DC) programming (S-DCP) algorithm for learning the GB-RBM.We present extensive empirical studies on several benchmark datasets tovalidate the performance of this S-DCP algorithm. It is seen that S-DCP isbetter than the CD and PCD algorithms in terms of speed of learning and thequality of the generative model learnt.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # create a database connection\n",
    "    conn = create_connection(database)\n",
    "    with conn: \n",
    "        drop_Resources_table(conn) \n",
    "        \n",
    "        create_Resources_table(conn)        \n",
    "        \n",
    "        import_from_csv_to_table(conn)        \n",
    "        \n",
    "        print(\"Here is 2 rows of table:\")\n",
    "        select_2_rows_resource(conn)\n",
    "        \n",
    "    conn.commit()\n",
    "    conn.close()    \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
